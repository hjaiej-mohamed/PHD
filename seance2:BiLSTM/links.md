1.Deep Learning For NLP: Zero To Transformers & BERT:

https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert#Bi-Directional-RNN's

2.Bidirectional LSTM-CRF Models for Sequence Tagging:

https://arxiv.org/pdf/1508.01991.pdf

3.What happens when you write LSTM:

https://www.kaggle.com/code/elmahy/what-happens-when-you-write-lstm#Step1--%3E-Create-the-LSTMCell-layer

4.TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models:

https://arxiv.org/pdf/2109.10282v5.pdf

5.Connectionist Temporal Classification with Maximum Entropy Regularization:

https://proceedings.neurips.cc/paper_files/paper/2018/file/e44fea3bec53bcea3b7513ccef5857ac-Paper.pdf
