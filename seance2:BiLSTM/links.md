1.Deep Learning For NLP: Zero To Transformers & BERT:

https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert#Bi-Directional-RNN's

2.Bidirectional LSTM-CRF Models for Sequence Tagging:

https://arxiv.org/pdf/1508.01991.pdf

3.What happens when you write LSTM:

https://www.kaggle.com/code/elmahy/what-happens-when-you-write-lstm#Step1--%3E-Create-the-LSTMCell-layer

4.TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models:

https://arxiv.org/pdf/2109.10282v5.pdf

